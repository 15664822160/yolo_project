import sys
import os
from PyQt5.QtWidgets import *
from PyQt5.QtCore import *
from PyQt5.QtGui import *
from ultralytics import YOLO
from wxauto import WeChat
import queue
import cv2


class MyWindow(QWidget):
    def __init__(self):
        super().__init__()
        #çª—å£å¤§å°
        self.resize(1200,800)
        #æ ‡é¢˜
        self.setWindowTitle("åŸºäºYolov8çš„äººä½“æ‘”å€’æ£€æµ‹ç³»ç»Ÿ")
        #çª—æ ‡
        self.setWindowIcon(QIcon("R-C.png"))
        #æ¨¡å‹
        self.model = YOLO(r'runs/detect/train2/weights/best.pt')
        # è®¡æ•°å™¨
        self.num = 0
        #æ ‡å¿—ä½ï¼Œæ§åˆ¶æ‘„åƒå¤´çš„å¼€å§‹å’Œæš‚åœ
        self.pua = False
        #åŒå‘é˜Ÿåˆ—ï¼Œåˆ¤æ–­æ˜¯å¦æ‘”å€’
        self.deq=queue.Queue()
        self.deq_wf=queue.Queue()
        #æ¦‚ç‡æ•°
        self.deq_fall=0
        self.init_ui()
        # è¿æ¥ä¿¡å·å’Œæ§½å‡½æ•°


    def init_ui(self):
        #æ€»å¸ƒå±€å™¨V_layout
        V_layout=QVBoxLayout()
        #ä¸Šå¸ƒå±€å™¨s_layout
        s_layout=QHBoxLayout()
        #ä¸¤ä¸ªæ–‡æœ¬æ¡†
        self.l1=QLabel()
        self.l2=QLabel()
        self.l1.setFixedSize(600,400)
        self.l2.setFixedSize(600,400)
        self.l1.setStyleSheet('border:1px solid #DDDDDD;')
        self.l2.setStyleSheet('border:1px solid #DDDDDD;')
        s_layout.addWidget(self.l1)
        s_layout.addWidget(self.l2)
        #ä¸‹ç»„zu
        zu=QGroupBox()
        #ä¸‹ç»„å¸ƒå±€å™¨x_layout
        x_layout=QHBoxLayout()
        #ä¸‹å·¦æ–‡æœ¬æ¡†l3
        self.l3=QLabel()
        self.l3.resize(1000,20)
        self.l3.setWordWrap(True)#è‡ªåŠ¨æ¢è¡Œ
        self.l3.setAlignment(Qt.AlignTop)#é¡¶æ ¼
        # åˆ›å»ºä¸€ä¸ª QScrollArea æ»‘åŠ¨çª—æ ¼
        scr = QScrollArea()
        scr.setWidgetResizable(True) #?
        # å…è®¸æ»šåŠ¨åŒºåŸŸå†…çš„éƒ¨ä»¶è°ƒæ•´å¤§å°
        scr.setWidget(self.l3)  # å°† QLabel æ·»åŠ åˆ°æ»šåŠ¨åŒºåŸŸä¸­
        #æ»šåŠ¨å¸ƒå±€å™¨
        v_layout=QVBoxLayout()
        v_layout.addWidget(scr)
        x_layout.addLayout(v_layout)
        #ä¸‹å³å¸ƒå±€å™¨xv_layout
        xv_layout=QVBoxLayout()
        p1=QPushButton("ğŸ¤–æ¨¡å‹é€‰æ‹©")
        p2=QPushButton("ğŸï¸è§†é¢‘æ–‡ä»¶")
        p3=QPushButton("ğŸ“¹æ‘„åƒå¤´")
        p4=QPushButton("ğŸ“·ç…§ç‰‡æ–‡ä»¶")
        self.p5_p=QPushButton("ğŸ›‘åœæ­¢")
        p1.clicked.connect(self.p1)
        p2.clicked.connect(self.p2)
        p3.clicked.connect(self.p3)
        p4.clicked.connect(self.p4)
        self.p5_p.clicked.connect(self.p5)
        xv_layout.addWidget(p1)
        xv_layout.addWidget(p2)
        xv_layout.addWidget(p3)
        xv_layout.addWidget(p4)
        xv_layout.addWidget(self.p5_p)
        x_layout.addLayout(xv_layout)
        zu.setLayout(x_layout)
        V_layout.addLayout(s_layout)
        V_layout.addWidget(zu)
        self.setLayout(V_layout)
        self.l4=QLabel(self)


    def p1(self):
        file_dg = QFileDialog()
        file_model, _ = file_dg.getOpenFileName(self, 'é€‰æ‹©å›¾åƒæ–‡ä»¶', '','æ¨¡å‹æ–‡ä»¶ (*.pt)')
        if file_model:
            self.model = YOLO(file_model)
        else:
            print('æœªé€‰æ‹©æ¨¡å‹')


    def p2(self):
        file_dialog = QFileDialog()
        video_path, _ = file_dialog.getOpenFileName(self, 'é€‰æ‹©è§†é¢‘æ–‡ä»¶', '', 'è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mov)')
        if video_path:
            self.p2_openvideo(video_path)
        else:
            print("æœªé€‰æ‹©è§†é¢‘æ–‡ä»¶")

    def p2_openvideo(self, video_path):
        self.cap = cv2.VideoCapture(video_path)
        if self.cap.isOpened():
            # åˆ›å»ºå®šæ—¶å™¨
            self.timer = QTimer(self)
            self.timer.timeout.connect(self.p2_update_frame)
            # å¯åŠ¨å®šæ—¶å™¨ï¼Œæ¯éš”30æ¯«ç§’æ›´æ–°ä¸€æ¬¡å¸§
            self.timer.start(30)
        else:
            print("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")

    def p2_update_frame(self):
        if not self.pua:
            if self.cap.isOpened():
                # è¯»å–ä¸€å¸§è§†é¢‘
                ret, frame = self.cap.read()
                print()
                if ret:
                    #å·¦å›¾
                    # å°†OpenCVçš„BGRæ ¼å¼è½¬æ¢ä¸ºRGBæ ¼å¼
                    frame1 = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    # è·å–å¸§çš„é«˜åº¦ã€å®½åº¦å’Œé€šé“æ•°
                    height, width, channel = frame1.shape
                    # è®¡ç®—å­—èŠ‚æ•°
                    bytes_per_line = 3 * width
                    # åˆ›å»ºQImageå¯¹è±¡
                    q_img = QImage(frame1.data, width, height, bytes_per_line, QImage.Format_RGB888)
                    # åˆ›å»ºQPixmapå¯¹è±¡
                    pixmap = QPixmap.fromImage(q_img)
                    #æŒ‰æ¯”ä¾‹æ”¾å…¥l1
                    scaled_pixmap = pixmap.scaled(self.l1.width(), self.l1.height(), Qt.KeepAspectRatio)
                    # åœ¨æ ‡ç­¾ä¸­æ˜¾ç¤ºå›¾åƒ
                    self.l1.setPixmap(scaled_pixmap)
                    #å³å›¾
                    #å¯¼å…¥æ¨¡å‹
                    results = self.model(frame1, conf=0.6)
                    annotated_frame = results[0].plot()  # ç”»æ¡†
                    info_text = ""
                    res_name=""
                    for box in results[0].boxes:
                        class_id = int(box.cls[0])
                        class_name = results[0].names[class_id]
                        res_name=class_name
                        confidence = float(box.conf[0])
                        info_text += f"ç±»åˆ«: {class_name}, ç½®ä¿¡åº¦: {confidence:.2f}\n"
                    if self.deq_fall >= 100:
                        self.l4.setStyleSheet("color: red;")
                        self.l4.setText(str(self.deq_fall))
                    else:
                        self.l4.setStyleSheet("color: black;")
                        self.l4.setText(str(self.deq_fall))
                    if self.deq_fall > 120:  # å¦‚æœ200å¸§å›¾åƒä¸­æœ‰è¶…è¿‡60%éƒ½æ˜¯æ‘”å€’ï¼Œåˆ™æŠ¥è­¦
                        self.WeChat()  # å‘é€è­¦æŠ¥
                        self.deq = queue.Queue()
                        self.deq_wf = queue.Queue()
                        self.deq_fall=0
                    #é˜Ÿåˆ—åˆ¤æ–­æ‘”å€’ï¼Œç”Ÿæˆè§†é¢‘
                    if self.deq_wf.qsize()>200:#å¦‚æœé˜Ÿåˆ—ä¸­çš„å›¾ç‰‡å¤§äº200å¸§
                        if not self.deq.empty():
                            self.deq.get()#å»é™¤ç¬¬1ä¸ªå›¾ç‰‡
                            if self.deq_wf.get()==0:#å¦‚æœç¬¬1ä¸ªå›¾ç‰‡æ˜¯æ‘”å€’
                                self.deq_fall-=1

                    self.deq.put(frame)#æ–°æ¥çš„å›¾ç‰‡
                    if res_name=="walk":#åˆ¤æ–­å›¾ç‰‡äººä½“ç«™ç€å°±æ˜¯1
                        self.deq_wf.put(1)
                    elif res_name=="fall":#åˆ¤æ–­å›¾ç‰‡äººä½“å€’äº†å°±æ˜¯0
                        self.deq_wf.put(0)
                        self.deq_fall+=1#200å¸§å›¾åƒä¸­æ‘”å€’æ¬¡æ•°
                    else:
                        self.deq_wf.put(2)
                    height, width, channel = annotated_frame.shape  # è·å–ä¸‰ç»´
                    bytes_per_line = 3 * width
                    # print("annotated_frame.data",type(annotated_frame.data))#å…¶ä»–æ ¼å¼
                    q_img = QImage(annotated_frame.data, width, height, bytes_per_line, QImage.Format_RGB888)
                    # print("q_img",type(q_img))#QImageæ ¼å¼
                    pixmap = QPixmap.fromImage(q_img)
                    sc_pixmap = pixmap.scaled(self.l1.width(), self.l1.height(), Qt.KeepAspectRatio)
                    # print("pixmap",type(pixmap))#QPixmapæ ¼å¼

                    self.l2.setPixmap(sc_pixmap)
                    self.num += 1
                    self.l3.setText(self.l3.text() + "\n" + f"ç¬¬{self.num}å¼ å›¾åƒ  " + info_text)
                else:
                    # åœæ­¢å®šæ—¶å™¨
                    self.timer.stop()
                    # é‡Šæ”¾è§†é¢‘æ•è·å¯¹è±¡
                    self.cap.release()


    def p3(self):
        self.cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)
        if not self.cap.isOpened():
            print("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            return
        # åˆ›å»ºä¸€ä¸ªå®šæ—¶å™¨ï¼Œç”¨äºå®šæ—¶æ›´æ–°è§†é¢‘å¸§
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.p3_updateFrame)
        self.timer.start(30)  # æ¯ 30 æ¯«ç§’æ›´æ–°ä¸€æ¬¡å¸§

    def p3_updateFrame(self):
        if not self.pua:
            ret, frame = self.cap.read()
            # print("frame",type(frame))#numpyæ ¼å¼
            if ret:
                # å°† BGR æ ¼å¼è½¬æ¢ä¸º RGB æ ¼å¼
                frame1 = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                # è·å–å¸§çš„é«˜åº¦ã€å®½åº¦å’Œé€šé“æ•°
                height, width, channel = frame1.shape
                # è®¡ç®—æ¯è¡Œçš„å­—èŠ‚æ•°
                bytesPerLine = 3 * width
                # åˆ›å»º QImage å¯¹è±¡
                qImg = QImage(frame1.data, width, height, bytesPerLine, QImage.Format_RGB888)
                # åˆ›å»º QPixmap å¯¹è±¡
                pixmap = QPixmap.fromImage(qImg)
                # åœ¨æ ‡ç­¾ä¸­æ˜¾ç¤ºå›¾åƒ
                self.l1.setPixmap(pixmap)

                #å³å›¾
                # print("frame1",type(frame1))#numpyæ ¼å¼
                results = self.model(frame1, conf=0.6)
                annotated_frame = results[0].plot()#ç”»æ¡†
                info_text = ""
                for box in results[0].boxes:
                    class_id = int(box.cls[0])
                    class_name = results[0].names[class_id]
                    confidence = float(box.conf[0])
                    info_text += f"ç±»åˆ«: {class_name}, ç½®ä¿¡åº¦: {confidence:.2f}\n"

                height, width, channel = annotated_frame.shape#è·å–ä¸‰ç»´
                bytes_per_line = 3 * width
                # print("annotated_frame.data",type(annotated_frame.data))#å…¶ä»–æ ¼å¼
                q_img = QImage(annotated_frame.data, width, height, bytes_per_line, QImage.Format_RGB888)
                # print("q_img",type(q_img))#QImageæ ¼å¼
                pixmap = QPixmap.fromImage(q_img)
                # print("pixmap",type(pixmap))#QPixmapæ ¼å¼


                self.l2.setPixmap(pixmap)
                self.num+=1
                self.l3.setText(self.l3.text()+"\n"+f"ç¬¬{self.num}å¼ å›¾åƒ  "+info_text)


    def p4(self):
        file_dialog = QFileDialog(self)
        file_path, _ = file_dialog.getOpenFileName(self, 'é€‰æ‹©å›¾ç‰‡', '', 'å›¾åƒæ–‡ä»¶ (*.png *.jpg)')
        if file_path:
            frame_pic = cv2.imread(file_path)
            frame_pic = cv2.cvtColor(frame_pic, cv2.COLOR_BGR2RGB)
            pixmap = QPixmap(file_path)
            if not pixmap.isNull():
                #Qt.KeepAspectRatioç¼©æ”¾å›¾åƒæˆ–è°ƒæ•´æ§ä»¶å¤§å°æ—¶ï¼Œä¿æŒå…¶åŸå§‹çš„å®½é«˜æ¯”
                scaled_pixmap = pixmap.scaled(self.l1.width(), self.l1.height(), Qt.KeepAspectRatio)
                self.l1.setPixmap(scaled_pixmap)
                res = self.model(frame_pic, conf=0.6)
                ident = res[0].plot()  # ç”»æ¡†
                info_text = ""
                for box in res[0].boxes:
                    class_id = int(box.cls[0])
                    class_name = res[0].names[class_id]
                    confidence = float(box.conf[0])
                    info_text += f"ç±»åˆ«: {class_name}, ç½®ä¿¡åº¦: {confidence:.2f}\n"

                height, width, channel = ident.shape  # è·å–ä¸‰ç»´
                line = 3 * width
                img = QImage(ident.data, width, height, line, QImage.Format_RGB888)
                pixmap = QPixmap.fromImage(img)
                sc_pixmap = pixmap.scaled(self.l2.width(), self.l2.height(), Qt.KeepAspectRatio)
                self.l2.setPixmap(sc_pixmap)
                self.num += 1
                self.l3.setText(self.l3.text() + "\n" + f"ç¬¬{self.num}å¼ å›¾åƒ  " + info_text)
            else:
                print('æ— æ³•åŠ è½½å›¾åƒ')
        else:
            print('æœªé€‰æ‹©å›¾åƒæ–‡ä»¶')


    def p5(self):
        self.pua=not self.pua
        if self.pua==False:
            self.p5_p.setText("ğŸ›‘åœæ­¢")
        else:
            self.p5_p.setText("â–¶ï¸ç»§ç»­")

    def WeChat(self):
        def images_to_mp4(image_queue, output_path, fps=20, width=640, height=480):
            # å®šä¹‰è§†é¢‘ç¼–ç å™¨
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            # åˆ›å»º VideoWriter å¯¹è±¡
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

            while not image_queue.empty():
                # ä»é˜Ÿåˆ—ä¸­è·å–å›¾ç‰‡
                image = image_queue.get()
                # è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥åŒ¹é…è§†é¢‘å°ºå¯¸
                resized_image = cv2.resize(image, (width, height))
                # å°†å›¾ç‰‡å†™å…¥è§†é¢‘æ–‡ä»¶
                out.write(resized_image)

            # é‡Šæ”¾ VideoWriter å¯¹è±¡
            out.release()

        try:
            # è·å–ç”¨æˆ·ä¸»ç›®å½•
            home_dir = os.path.expanduser("~")
            output_video_path = os.path.join(home_dir, "Desktop", "fall.mp4")
            # è°ƒç”¨å‡½æ•°å°†é˜Ÿåˆ—ä¸­çš„å›¾ç‰‡è½¬æ¢ä¸º MP4 è§†é¢‘
            images_to_mp4(self.deq, output_video_path, fps=25, width=800, height=600)
            # åˆå§‹åŒ–å¾®ä¿¡å¯¹è±¡
            wx = WeChat()
            video_path = output_video_path
            who = 'æ–‡ä»¶ä¼ è¾“åŠ©æ‰‹'
            wx.SendMsg(msg="æ£€æµ‹åˆ°æœ‰äººæ‘”å€’", who=who)
            wx.SendFiles(filepath=(video_path,), who=who)
        except Exception as e:
            print(f"åœ¨ Wechat æ–¹æ³•ä¸­å‡ºç°å¼‚å¸¸: {e}")



if __name__ == '__main__':
    app = QApplication(sys.argv)
    w = MyWindow()
    w.show()
    app.exec()
